---
title: DEN - 2022-10-28
feed: hide
---

- [지속적 전달·통합은 구름과 찰떡궁합··· 클라우드 CI/CD 플랫폼 안내서](https://www.itworld.co.kr/news/261832?page=0%2C0&fbclid=IwAR0f629TwISyyNvVtzAXmcO2x5siwrL9046Sw7MA5sxQZpGfUAW0_8b_fj8)
	- 근데 뭐 당연히 클라우드에서 쿠버네티스에 올리는게 CD 파이프라인으론 제일 편하지 않나?
	- 코드 파이프라인같은 아마존 서비스로 깃허브도 땡겨올 수 있구나
		- 근데 이렇게 구성하는게 낫지 않나 싶다. [Deploying to Amazon Elastic Container Service](https://docs.github.com/en/actions/deployment/deploying-to-your-cloud-provider/deploying-to-amazon-elastic-container-service)
- [딥 러닝 모델 Serving 간단 구축기 (feat. AWS SQS + Python Application + Kubernetes + Git & Rancher)](https://tech.socarcorp.kr/data/2020/03/10/ml-model-serving.html)
	- 플랫폼을 통한 서빙을 사용하는 게 빠른 시간에 하기엔 오히려 좀 어려울 수 있다.
	- 안정적인 서빙과 커스터마이징 측면에서는 오히려 새롭게 만드는 편이 나을 수도 있다.
	- 인터페이스를 API Gateway로 사용하는게 좋을 수도 있다고 하시긴 했는데, 일단은 설정이 편한 SQS쪽으로 써도 될 것 같다.
		- 좀 더 자세한 아키텍처가 궁금하긴 한데, 뭐 일단 지금은 내가 어쩔수가 없다.

- [Kurly만의 MLOps 구축하기 - 초석 다지기](https://helloworld.kurly.com/blog/first-mlops/)
	- MLOps는 ML 시스템을 운영하기 위해 DevOps의 원칙을 적용한 것이다.
		- 규모에 따라 필요한 인프라의 정도는 달라지게 된다.
	- 클라우드에서 쿠버네티스 학습 환경 구현할 때 문젠 GPU 자원 할당이다.
		- 이걸 자동으로 관리하기 위한 솔루션이 필요할 것 같다.
			- 나도 Sagemaker에 대가리 한 번 깨지고 나니까 이 부분에 대해서는 충분히 공감이 되는 것 같다.
	- EKS는 EC2 기반으로 elastic하게 노드 가져다 쓸 수 있어서 오토 스케일링이 확실히 편해지는 것 같다.
		- 클라우드 기술이 진짜 많이 발전한 것 같긴 하다. GKE 오토파일럿 쓰면서 느꼈다.
	- Karpenter는 쿠베 워커노드 자동 확장 기능 하는데, 새롭게 배포될 팟을 지속적으로 체크하고 워커 노드가 부족하면 추가 배포하고 확장하며, 불필요한 노드까지 정리한다고 한다.
		- 일반적인 오토스케일링은 클라우드 서버의 컴퓨팅 엔진 통해서 노드 확장했다.
		- Karpenter는 오토 스케일링 과정에서 Cloud Provider의 기능을 연계할 필요가 없다.
			- 오토 스케일링에서 많은 기능을 직접 처리해버린다.
		- Karpenter는 4개의 주요 기능을 가진다.
			- Watching : pod 자체의 상태를 체크하고, 스케줄링 안되는 팟 확인한다.
			- Evaluating : pod의 스케줄 가용성을 확인한다.
			- Provisioning : 요구사항에 맞는 노드를 pod에 배포한다.
			- Removing : 노드 필요 없으면 삭제한다.
		- Provisioner는 Custom Resource에 대해 작성한거다.
			- 노드의 제약사항이나 필요 없는 설정들, timeout등을 설정한다.
			- 이때 Taints로 GPU 넣어서 GPU 달린 서버로 프로비저닝 하도록 할 수도 있다.
	- Deprovisioning에서 affinity 옵션을 통해 문제를 해결할 수 있다.
		- GPU 관련 없는 pod가 gpu 있는데 붙으면 신나는거다.
		- Affinity로 이거 안붙게 할 수 있다. [[K8s - Monitoring and Logging]]

- 쿠버네티스 프로젝트 겸 해서 연구실 새 서버 들어오면 두개 클러스터로 묶고 Kubeflow 서빙해서 연구용 서버 만드는거 생각해 봐야겠다.
	- prometheus에 kubeflow 쓰면 뭐 어찌어찌 되지 않을까?
	- 할당 관리가 생각보다 엄청나게 어려운 것 같다.


- Nest 이용하여 Producer 세팅하기 [@nestjs-packages/sqs](https://github.com/nestjs-packages/sqs)
	- IAM에서 먼저 엑세스 키 먼저 발급 받아야 한다.
		- 보안 생각하면 계정 따로 만들어서 발급하는게 좋을 것 같아서, API 서버 사용하기 위해 SQS랑 RDS만 접근할 수 있는 계정 하나 새로 만들어서 이걸로 로그인하게 했다.
	- 우선은 코드 주어진 그대로 따라 쳤다.
		- 일단은 무지성으로 때려넣어 보고, 그 이후에 어떻게 처리할 지 생각하면 될 것 같다.
		- 컨슈머는 boto 라이브러리 쓸 수 있어서 다행인 것 같다.
	- 근데 아키텍처적으로 좀 이상해지긴 한데.
		- 모델이고 api고 다 쿠버네티스에 올릴거면서, db랑 메시징 큐는 관리형 db 쓰네?
	- 항상 cors 설정은 조심하도록 하자. [NestJS | CORS 설정](https://velog.io/@suasue/NestJS-CORS-%EC%84%A4%EC%A0%95)
	- 설정하다 진짜 이런저런 문제 다 겪는 것 같다. [Amazon SQS 대기열에 API를 호출할 때 QueueDoesNotExist 오류를 해결하려면 어떻게 해야 합니까?](https://aws.amazon.com/ko/premiumsupport/knowledge-center/sqs-queuedoesnotexist-errors/)
	- 