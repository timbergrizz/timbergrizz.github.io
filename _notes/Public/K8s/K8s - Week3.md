---
title: K8s - Week3
feed: hide
---

- 컨테이너 죽을때는 여러가지 경우가 발생할 수 있다.
	- 트랜적션 정리 못하고 그냥 죽어버리거나 하면 신나는거다.
	- 그래서 Hook등의 이벤트등을 통해 종료될 때의 시간 지연을 발생시키고 이를 바탕으로 할 수 있다
- autopilot 사용하더라도 모든 설정은 yaml 파일로 생성해주는 것이 좋다.
- 구글 쿠버네티스는 두개의 모드가 있다.
	- 스탠다드는 노드가 관리형 서비스가 아니라, 직접 관리해주어야 한다.
	- 오토 파일럿은 노드 또한 자동 관리형이다.
		- 노드 풀을 관리형 서비스로 들어가서, pod 단위로 관리되어 비용이 절약될 수 있다.
- private cluster의 경우 authorized network만 인바운드를 받을 수 있다.
	- 클러스터에 클라우드 쉘의 포트를 받아줄 수 있도록 포트를 받아주면 된다. [공식 문서](https://cloud.google.com/kubernetes-engine/docs/how-to/private-clusters#cloud_shell)
	- private cluster를 사용하는 것 자체는 좋은 practice.
- ingress controller가 여러가지 있는데, 뭐 쓸까?
	- 인그레스 컨트롤러는 인그레스 컨트롤러 쓰는게 맞고, 최적화된 걸 쓰면 된다.
	- 구글은 로드 밸런서 붙고, 로컬 환경에는 l7 스위치가 없어서 대안으로 nginx나 프록시같은거 쓰게 되는 것이다.
	- 일반적으로는 ingress controller를 사용해서 해결되는 것이 가장 좋은 상황이다.
		- 클라우드에서는 elb나 attp lb로 자동으로 생성이 된다.
		- 내부적으로 매핑이 되어있다고 할 수 있다.

## Scheduler

### Node Affinity
- 노드가 3개 있을 때,  gpu 레이블과 cpu 레이블이 있을 때, pod에서 node affinity에 따라 매칭되는 노드로 올리도록 할 수 있다.
- nodeAntiAffinity는 레이블에 해당하지 않는 곳으로만 데이터를 보내게 된다.![[Pasted image 20221018142504.png]]
	- 여러개의 영역이 있을 때, 특정 영역에 배포될 수 있도록 하는데 자주 사용된다.
- soft affinity는 거기로 우선적으로 보내는 것이다.
	- 거기로 안 갈수도 있고, way값에 따라 결정될 수 있다.
		- 배포될 수 없으면 다른데로 간다.
- 실제로 배포하면, 이렇게 배포되지 않을 수 있다.
	- 쿠베의 스케줄러는 여러가지 스케줄링 매커니즘을 합산한 후 노드를 구하기 때문에 달라질 수 있다.
	- selector-SpreadPrority function이 있어, 여러 개의 node에 최대한 분포하고자 한다.
- topology 키를 따라 배포할 수 있다.
	- pod가 배포되어 있는 노드를 찾은 후, 여기로 배포가 되도록 할 수 있다.
- pod anti affinity를 통해 이미 있는 곳에는 배포하지 않도록 할 수 있다.
	- anti affinity를 확인하여 배포되지 않도록 설정할 수도 있다.
- 대단히 유용한 배포 기능이다.
	- 이를 사용하는지 여부에 따라 엔지니어의 수준이 결정될 수 있다.
	- 일반적인 엔지니어는 그냥 배포 갈기는데, 그렇게 써도 크게 문제는 안된다.
		- 근데 운영 상에서 몰리는 상황이 발생하지 않도록 하면, 가용성 등에서 이점을 볼 수 있다.
- 서버가 여러개 있을 때, pod를 배포했을 때 pod label와 topology key를 통해 여러 가용영역에 분포하여 보낼 수 있다.
	- 하나의 포드가 분리되어 배포되었을 때, 다른 포드를 같은 곳으로 붙이도록 구성할 수 있다.
	- affinity와 anti affinity를 같이 주어 하나씩만 배포되도록 할 수 있다.
		- 사실은 sidecar로 두개 묶어서 배포하면 된다.
		- 이렇게 할 일이 생기는 경우가 있다.
			- 개발의 주체에 따라 달라진다.
				- 다른 어플리케이션 서버일 때, 2개의 팀이 개발한 config를 하나에 묶는게 더 골때릴 수 있다.
				- 이런 경우는 affinity로 묶어서 따로 pod로 묶어서 배포하는 경우가 나을 수 있다.
		- pod의 권한 문제로 이렇게 배포해야 하는 경우도 생긴다.
			- kernal access의 여부에 따라 pod를 분리해야 한다.
				- security level에 따라서 pod가 분리 될 수 있도록 해야 한다.

## Auto Scaling
- 쿠베 오토스케일러는 3개가 동작한다.
	1. node
		- 노드의 개수를 조정한다
	2. pod - vertica
		- pod의 개수를 늘린다
	3. pod - horizontal
		- 실제 request의 값을 늘려, 자원을 더 많이 할당하도록 한다.

### Node Pool
- 노드는 다른 하드웨어로 묶을 수 있다.
	- auto scaling은 노드 풀의 단위로 묶는다
		- 모자란 단위로 증가하게 되는 것이다.
	- 다른 클라우드와 다르게 구글은 multi-regional pool로 생성할 수 있다.
	- 하나의 쿠버네티스 풀을 만들고, 존만 분리해주는 방식으로 배포할 수 있는 것이다.
- 노드 스케일 아웃이 발생하는건 언제인가?
	- pod 생성하려는데 node 자원 모자라서 생성 안되고 pending이 발생할 때 문제가 된다.
- auto-scaling은 주기적으로 node pool이 놀고 있으면 내린다.
	- 돌던거는 내리고 다른 노드에 다시 올린다.
		- 일반적으로 stateless 프로그램은 문제가 없는데, db를 이렇게 쓰는건 좋지 않다.
		- 노드풀을 나누어서 scale-out이 되는 stateless 풀과 안되는 stateful 풀을 사용하는 것이 좋다.
	- stateful 풀은 io / cpu intensive한 경우가 많아 성능을 많이 할당해야 하고, stateless는 싸게 막는 경우가 좋다.

### Horizontal Pod Autoscaler
- auto scaler 만들고 min / max 정해서 pod 늘리도록 하는 것이다.
	- 이게 사실 제일 무식한 방법이다.
	- idleThread < 5이면 쓰레드가 거의 다 돌고 있는거다.
		- 스레드 수를 바탕으로 스케일링을 할 수 있으면 최선인데, 복잡한다.
	- message queue에 worker 쓰는데, 이거 찼다는 소리는 worker가 소화가 안된다는 뜻으로 이걸로 확인할 수 있다.
		- [keda](https://keda.sh/docs/2.8/scalers/redis-lists/](https://keda.sh/docs/2.8/scalers/redis-lists/) 등을 사용해 worker node의 부하를 확인하고, 이를 해결하도록 할 수 있다.
		- 스케일할 수 있는 back worker node를 만들 수 있따.

### Vertical Pod Autoscaler
- Pod의 수와 메모리를 조정한다.
	- Auto mod와 manual mod가 있다.
		- auto는 필요할때마다 올리는데, 이게 자동으로 껐다 켠다.
	- manual은 필요한 양을 확인하고, 스케일업 안하고 이걸 보여주기만 한다.
		- 이걸로 부하 테스트하고, 이를 통한 적절한 cpu 양을 확인해서 이를 통해 pod를 튜닝하고, hpa만 작동시키면 된다.
	- vpa / hpa 두개 같이 쓰는건 별로다.

- 비용 측면에서, 같은 zone에 필요한 것은 같은 zone으로 배치하는 등으로 처리할 수 있다.
	- regional service에서는 묶어서 쓰는게 낫다.
	- 노드 양은 매니지가 되기 때문에 이건 생각할 필요 없고, hpa만 생각하면 된다.
- 보통 머신러닝 엔지니어 gpu 사주면 안하고 게임하거나 비트코인 마이닝 돌린다.
	- 제대로 된 것은 트레이닝 돌리고 있겠지?

## Monitoring
- 모니터링은 그냥 관리형 솔루션 쓰는게 정답이다.
	- 프로메테우스를 주로 사용한다.
- 쿠버네티스뿐만이 아니라, 전체적인 프로덕션 환경의 문제인데, 혹시 모니터링 해본적 있음?
	- 회사에 모니터링 서비스가 존나게 많다.
		- 왜 그렇게 많을까? 사람이 달라져서 그렇다.
		- 운영을 하는 사람마다 보고자 하는 지표가 다르고, 그렇게 때문에 여러개의 모니터링 서비스를 사용하게 된다.
			- 처음에 셋업 잘해서 전체를 다 볼 수 있는걸 구축하면 되는데, 그게 아니라 사람마다 구축을 하게 된다.
	- 응답 시간이라고 해도, 조직마다 의미가 달라질 수 있게 된다.
		- 시간으로 찍히는 것 자체가 달라지게 된다.
		- 같은 어플리케이션에서 같은 기능의 응답시간의 수치가 다 달라지고, 이러면 혼란스러워 지는 것이다.
			- 무슨 툴을 쓰는지가 중요한게 아니라, 어떤 것을 모니터링 할 것이고, 지표의 의미를 어떻게 정의할 것인지가 가장 중요하다.![[Pasted image 20221018151018.png]]
		- 다음과 같은 지표를 확인할 수 있어야 한다.
			1. 호스트 레벨의 수치
			2. 컨테이너 단위의 메트릭
			3. 어플리케이션의 메트릭
			4. 쿠버네티스의 이벤트
- 쿠버네티스 모니터링 솔루션으로는 프로메테우스 쓰는 경우가 제일 많다.
	- best practice는 그냥 벤더에서 제공하는거 쓰는거다.
	- 개인적으로는 datadoc이 제일 좋은 솔루션이고, 제일 비싸다.
		- 인터페이스가 직관적으로 잘 만들어져 있고, 지표들이 정말 잘 나온다.
		- 그래픽 형태로도 나오고, 여튼 짱짱이다.
- 가장 중요한 것은 어떤 메트릭을 모니터링할 것인지가 중요하다.
	- SRE를 보면 메트릭을 어떻게 정하는지 방법론이 나온다.
		- [공식 문서](https://sre.google/) 랑 [책]([https://sre.google/books/](https://sre.google/books/))들 읽어보면 좋다.
	- SLI에 대해 다음과 같은 지표가 존재한다.
		- request latency
		- error rate
		- throughput
		- availability
		- durability
	- 이러한 메트릭은 워크로드 따라 스타일이 존재한다.
		- 모바일에서는 가용성, 레이턴시, 쓰루풋을 본다.
		- 빅데이터는 쓰루풋, 엔드투 엔드 지연시간을 확인한다.
			- 배치 타이밍 등을 확인한다.
			- 밤에 연산해서 추천 리스트 뽑아내는데 걸리는 시간을 확인한다.
		- ML은 user-facing과 동일한데, 모델 학습 시간을 봐야 한다.
	- SLI의 대표값은 어떻게 정할까?
		- average를 가장 많이 쓰고, 중간값도 많이 쓴다.
			- 이건 좋지 않은 방법이다.
			- 응답 시간 그래프를 볼때, 문제는 느린 순간의 응답 시간에서 발생한다.
		- avg time만 가지고 보게 되면, 문제점을 놓칠 수 있다.
			- percentile이라고 하는데, 응답 시간이 가장 느린 구간과 평균을 같이 보는 것이 좋은 방법이다.
				- 중간 값으로 하나만 그리는 것이 아니다.
		- standardized indicator
			- 메트릭이 표준화 될 수 있어야 한다.
			- 회사 내 / 시스템 내에서 표준화를 할 필요가 있다.
				- 다음과 같은 접근 방법을 사용할 수 있다.![[Pasted image 20221018151909.png]]
				- aggregation -> 1분간의 평균을 가지고 한다.
				- 어떤 request에 대해 이루어지는지를 명확하게 정의해야 한다.
				- indicator 자체의 표준화를 해야한다.
		- 몇개의 SLI를 사용해야 하는가?
			- 여러개의 콜을 복합적으로 하는 경우가 존재한다.
			- 유저 별로 3-5개의 SLI를 사용하는 것이 좋다.
	- 다음으로 SLO를 봐야 한다.
		- SLO에 대한 타겟을 삽입하는 것이다.
			- SLI에 대한 목표를 설정하는 것이다.
		- SLO를 정하기 위해서, 어떤 지표를 봐야 한다.
			- API 콜이기 때문에 Req / Res 패턴으로 설정할 수 있다.
			- Availability를 어떻게 정할 것인가?
				- 얼마나 성공적으로 로드되었는가
					- 성공적인 로드에 대한 정의가 무엇인가?
					- 성공과 실패를 어디서 기록할 것인가?
			- Latency
				- 얼마나 빨리 로드됐나?
					- 빨리를 어떻게 정의할 것인가
					- 시작점과 종료점을 어떻게 정의할 것인가?
			- 위의 조건들을 다음과 같이 정의할 수 있다.![[Pasted image 20221018152457.png]]
			- 다음과 같이 정리하여 정의할 수 있다.![[Pasted image 20221018152515.png]]
		- 시스템이 많아지는 경우, 이를 커뮤니케이션하는게 어려워진다.
			- 다른 사람과 얘기할 때, 이게 어떤지를 설명할 수 없다.
				- 이를 표준화 할 수 있어야 한다.
				- Aggregated SLI로 하여, SLO를 맞췄으면 굿, 넘겼으면 past로 보는 것이다.
	- 좋은 모니터링은 응답 시간이 목표에 비해 어떻게 되는지 이해하는 것이다.
		- 모니터링은 운영에 대한 것 뿐만이 아니라, 조직의 문화에 대해서도 반영되게 된다.
			- 운영에 대한 책임감을 비즈니스 / 개발에서도 이해할 수 있도록 해야 한다.
	- 모니터링이 기술적으로는 그냥 많이 모아서 보여주면 된다.
		- 제일 어려운 것은 어떻게 이러한 걸 정의하고, 어떠한 인사이트를 뽑아내서 어떻게 비즈니스 팀과 소통할 것인지가 문제이다.

### Kubernetes Monitoring
- 크게 두가지 모니터링으로 나뉜다.
	- Core Metric : 쿠버네티스의 기본적인 Metric
		- 메모리 / CPU등으로 작동하낟.
- 예전에는 노드마다 cadvisor가 떠서 kubelet을 통해 heapster로 보냈다.
	- 현재는 구조가 바뀌어 cAdvisor에서 metric server로 보낸다.
		- metric server는 쿠베 안에 있는 서버이다.
			- 스토리지가 없고 메모리가 저장된다.
			- 중요한 core metric만 메모리에 저장하는 것이다.
				- historic한 정보는 볼 수 없다.
		- 사실은 full metric pipeline에는 모니터링 구성 방법이 많고, cadvisor + prometheus 쓰는게 제일 많다.
			- 프로메테우스가 오픈 소스중에서 de facto standard로 사용되는 구조이다.
	- 프로메테우스는 sdk 넣거나, 웹 api로 데이터 삽입하는 등의 방법을 사용할 수 있다.
		- cAdvisor를 통해 metirc을 저장할 수 있고, 이를 HTTP 서버를 통해 외부로 쿼리로 보낼 수 있다.
			- 외부에서 쿼리 랭귀지를 가져오도록 하는 것이다.
			- 프로메테우스에 넣고, 메모리에만 저장된 metric들을 넣고, node에 대한 정보 가져오고, 모든 정보 가져와서 프로메테우스에 콘솔레이트 한다.
	- 보통은 프로메테우스에서 모니터링 할 수 있는 pod가 올라온다.
		- 이거 쓰면 안된다.
			- pod로 떠봐야 한정되어 있어, 별도의 모니터링 시스템 따로 사용하는 것이 좋다.
			- 프로메테우스는 노드안에 pod로 뜨는데, 프로메테우스가 클러스터링이 안되고, 그렇기 때문에 내려가면 모니터링이 안되는 것이다.
				- 프로메테우스가 죽으면 어쩔가임?
					- 다른 인스턴스가 받아서 할 수 있는 구조가 될 수 있어야 한다.
					- HA Proxy 넣어서 트래픽을 미러링하고, 기술적으로 이렇게 극복할 수는 있다.
					- 프로메테우스는 클러스터링이 안되어, 용량 이상으로 저장할 수 없다.
				- [thanos]([https://thanos.io/](https://thanos.io/))라는 여러개의 클러스터를 묶을 수 있는 솔루션이 나왔는데도 힘들다.
				- 걍 매니지드 써라.
					- 프로메테우스랑 똑같이 보이는데, 속은 다르게 작동시킬 수 있다.
					- 구글의 경우는 쿠버네티스 깔면 metric agent가 떠서 그 안으로 보내고, 프로메테우스 껍데기 붙여서 프로메테우스처럼 보이도록 한다.
						- 뒷쪽은 드라이브들이 떠있는 것이다.

## Logging

- elasticsearch와 유사하다.
- 로깅 시스템이라는게, 여러가지가 텍스트로 나오는게 옛날 로깅 시스템 아키텍처이다.
	- 요새는 데이터 파이프라인에 넣기 위한 용도로 사용한다.
	- 응답 시간 / 데이터 보내기 위한 시간 json식으로 넣는다.
		- 어떤 데이터는 빅데이터 시스템 / 어떤 데이터는 머신러닝 시스템으로 파이프라이닝을 할 수 있다.
	- 구글의 경우는 로그를 읽은 후 bigquery에 넣어 sql을 분석하도록 할 수 있다.
- 구글의 경우는 json으로 로그 만들었으면, 하나하나의 쿼리를 매핑을 해준다.
	- 요즘은 json 형태의 로그 포맷을 쓰는것이 유행이다.
	- 자바에서 log4j로는 안되고, [이렇게](https://bcho.tistory.com/m/1313)  사용하는 것이 좋다
	- 그라파나를 통해 플 시각화를 수행할 수 있다.
		- 개인정보같은거 로그에 포함되는 순간 신나게 된다.
	- DLP라는 ML API가 있어, 텍스트 정보를 스캔하여 개인정보를 탐지하는 어플리케이션들이 있다.
		- 이거랑 로그를 연결해서, 처리할 수 있다.
- 로그 들어오면, 이걸 저장한 후 DLP로 넘겨 개인정보 들어왔는지 판단한다.
	- 대시보드로는 개인정보가 제거되었는 데이터를 보내게 된다.
		- 데이터가 계속 바뀌도록 조치해야 한다.

