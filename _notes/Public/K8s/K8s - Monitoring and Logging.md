---
title: K8s - Monitoring and Logging
feed: hide
---


## Monitoring
- 모니터링은 그냥 관리형 솔루션 쓰는게 정답이다.
	- 프로메테우스를 주로 사용한다.
- 쿠버네티스뿐만이 아니라, 전체적인 프로덕션 환경의 문제인데, 혹시 모니터링 해본적 있음?
	- 회사에 모니터링 서비스가 존나게 많다.
		- 왜 그렇게 많을까? 사람이 달라져서 그렇다.
		- 운영을 하는 사람마다 보고자 하는 지표가 다르고, 그렇게 때문에 여러개의 모니터링 서비스를 사용하게 된다.
			- 처음에 셋업 잘해서 전체를 다 볼 수 있는걸 구축하면 되는데, 그게 아니라 사람마다 구축을 하게 된다.
	- 응답 시간이라고 해도, 조직마다 의미가 달라질 수 있게 된다.
		- 시간으로 찍히는 것 자체가 달라지게 된다.
		- 같은 어플리케이션에서 같은 기능의 응답시간의 수치가 다 달라지고, 이러면 혼란스러워 지는 것이다.
			- 무슨 툴을 쓰는지가 중요한게 아니라, 어떤 것을 모니터링 할 것이고, 지표의 의미를 어떻게 정의할 것인지가 가장 중요하다.
		- 다음과 같은 지표를 확인할 수 있어야 한다.
			1. 호스트 레벨의 수치
			2. 컨테이너 단위의 메트릭
			3. 어플리케이션의 메트릭
			4. 쿠버네티스의 이벤트
- 쿠버네티스 모니터링 솔루션으로는 프로메테우스 쓰는 경우가 제일 많다.
	- best practice는 그냥 벤더에서 제공하는거 쓰는거다.
	- 개인적으로는 datadoc이 제일 좋은 솔루션이고, 제일 비싸다.
		- 인터페이스가 직관적으로 잘 만들어져 있고, 지표들이 정말 잘 나온다.
		- 그래픽 형태로도 나오고, 여튼 짱짱이다.
- 가장 중요한 것은 어떤 메트릭을 모니터링할 것인지가 중요하다.
	- SRE를 보면 메트릭을 어떻게 정하는지 방법론이 나온다.
		- [공식 문서](https://sre.google/) 랑 [책]([https://sre.google/books/](https://sre.google/books/))들 읽어보면 좋다.
	- SLI에 대해 다음과 같은 지표가 존재한다.
		- request latency
		- error rate
		- throughput
		- availability
		- durability
	- 이러한 메트릭은 워크로드 따라 스타일이 존재한다.
		- 모바일에서는 가용성, 레이턴시, 쓰루풋을 본다.
		- 빅데이터는 쓰루풋, 엔드투 엔드 지연시간을 확인한다.
			- 배치 타이밍 등을 확인한다.
			- 밤에 연산해서 추천 리스트 뽑아내는데 걸리는 시간을 확인한다.
		- ML은 user-facing과 동일한데, 모델 학습 시간을 봐야 한다.
	- SLI의 대표값은 어떻게 정할까?
		- average를 가장 많이 쓰고, 중간값도 많이 쓴다.
			- 이건 좋지 않은 방법이다.
			- 응답 시간 그래프를 볼때, 문제는 느린 순간의 응답 시간에서 발생한다.
		- avg time만 가지고 보게 되면, 문제점을 놓칠 수 있다.
			- percentile이라고 하는데, 응답 시간이 가장 느린 구간과 평균을 같이 보는 것이 좋은 방법이다.
				- 중간 값으로 하나만 그리는 것이 아니다.
		- standardized indicator
			- 메트릭이 표준화 될 수 있어야 한다.
			- 회사 내 / 시스템 내에서 표준화를 할 필요가 있다.
				- 다음과 같은 접근 방법을 사용할 수 있다.![[Pasted image 20221018151909.png]]
				- aggregation -> 1분간의 평균을 가지고 한다.
				- 어떤 request에 대해 이루어지는지를 명확하게 정의해야 한다.
				- indicator 자체의 표준화를 해야한다.
		- 몇개의 SLI를 사용해야 하는가?
			- 여러개의 콜을 복합적으로 하는 경우가 존재한다.
			- 유저 별로 3-5개의 SLI를 사용하는 것이 좋다.
	- 다음으로 SLO를 봐야 한다.
		- SLO에 대한 타겟을 삽입하는 것이다.
			- SLI에 대한 목표를 설정하는 것이다.
		- SLO를 정하기 위해서, 어떤 지표를 봐야 한다.
			- API 콜이기 때문에 Req / Res 패턴으로 설정할 수 있다.
			- Availability를 어떻게 정할 것인가?
				- 얼마나 성공적으로 로드되었는가
					- 성공적인 로드에 대한 정의가 무엇인가?
					- 성공과 실패를 어디서 기록할 것인가?
			- Latency
				- 얼마나 빨리 로드됐나?
					- 빨리를 어떻게 정의할 것인가
					- 시작점과 종료점을 어떻게 정의할 것인가?
			- 위의 조건들을 다음과 같이 정의할 수 있다.![[Pasted image 20221018152457.png]]
			- 다음과 같이 정리하여 정의할 수 있다.![[Pasted image 20221018152515.png]]
		- 시스템이 많아지는 경우, 이를 커뮤니케이션하는게 어려워진다.
			- 다른 사람과 얘기할 때, 이게 어떤지를 설명할 수 없다.
				- 이를 표준화 할 수 있어야 한다.
				- Aggregated SLI로 하여, SLO를 맞췄으면 굿, 넘겼으면 past로 보는 것이다.
	- 좋은 모니터링은 응답 시간이 목표에 비해 어떻게 되는지 이해하는 것이다.
		- 모니터링은 운영에 대한 것 뿐만이 아니라, 조직의 문화에 대해서도 반영되게 된다.
			- 운영에 대한 책임감을 비즈니스 / 개발에서도 이해할 수 있도록 해야 한다.
	- 모니터링이 기술적으로는 그냥 많이 모아서 보여주면 된다.
		- 제일 어려운 것은 어떻게 이러한 걸 정의하고, 어떠한 인사이트를 뽑아내서 어떻게 비즈니스 팀과 소통할 것인지가 문제이다.

### Kubernetes Monitoring
- 크게 두가지 모니터링으로 나뉜다.
	- Core Metric : 쿠버네티스의 기본적인 Metric
		- 메모리 / CPU등으로 작동하낟.
- 예전에는 노드마다 cadvisor가 떠서 kubelet을 통해 heapster로 보냈다.
	- 현재는 구조가 바뀌어 cAdvisor에서 metric server로 보낸다.
		- metric server는 쿠베 안에 있는 서버이다.
			- 스토리지가 없고 메모리가 저장된다.
			- 중요한 core metric만 메모리에 저장하는 것이다.
				- historic한 정보는 볼 수 없다.
		- 사실은 full metric pipeline에는 모니터링 구성 방법이 많고, cadvisor + prometheus 쓰는게 제일 많다.
			- 프로메테우스가 오픈 소스중에서 de facto standard로 사용되는 구조이다.
	- 프로메테우스는 sdk 넣거나, 웹 api로 데이터 삽입하는 등의 방법을 사용할 수 있다.
		- cAdvisor를 통해 metirc을 저장할 수 있고, 이를 HTTP 서버를 통해 외부로 쿼리로 보낼 수 있다.
			- 외부에서 쿼리 랭귀지를 가져오도록 하는 것이다.
			- 프로메테우스에 넣고, 메모리에만 저장된 metric들을 넣고, node에 대한 정보 가져오고, 모든 정보 가져와서 프로메테우스에 콘솔레이트 한다.
	- 보통은 프로메테우스에서 모니터링 할 수 있는 pod가 올라온다.
		- 이거 쓰면 안된다.
			- pod로 떠봐야 한정되어 있어, 별도의 모니터링 시스템 따로 사용하는 것이 좋다.
			- 프로메테우스는 노드안에 pod로 뜨는데, 프로메테우스가 클러스터링이 안되고, 그렇기 때문에 내려가면 모니터링이 안되는 것이다.
				- 프로메테우스가 죽으면 어쩔가임?
					- 다른 인스턴스가 받아서 할 수 있는 구조가 될 수 있어야 한다.
					- HA Proxy 넣어서 트래픽을 미러링하고, 기술적으로 이렇게 극복할 수는 있다.
					- 프로메테우스는 클러스터링이 안되어, 용량 이상으로 저장할 수 없다.
				- [thanos]([https://thanos.io/](https://thanos.io/))라는 여러개의 클러스터를 묶을 수 있는 솔루션이 나왔는데도 힘들다.
				- 걍 매니지드 써라.
					- 프로메테우스랑 똑같이 보이는데, 속은 다르게 작동시킬 수 있다.
					- 구글의 경우는 쿠버네티스 깔면 metric agent가 떠서 그 안으로 보내고, 프로메테우스 껍데기 붙여서 프로메테우스처럼 보이도록 한다.
						- 뒷쪽은 드라이브들이 떠있는 것이다.

## Logging

- elasticsearch와 유사하다.
- 로깅 시스템이라는게, 여러가지가 텍스트로 나오는게 옛날 로깅 시스템 아키텍처이다.
	- 요새는 데이터 파이프라인에 넣기 위한 용도로 사용한다.
	- 응답 시간 / 데이터 보내기 위한 시간 json식으로 넣는다.
		- 어떤 데이터는 빅데이터 시스템 / 어떤 데이터는 머신러닝 시스템으로 파이프라이닝을 할 수 있다.
	- 구글의 경우는 로그를 읽은 후 bigquery에 넣어 sql을 분석하도록 할 수 있다.
- 구글의 경우는 json으로 로그 만들었으면, 하나하나의 쿼리를 매핑을 해준다.
	- 요즘은 json 형태의 로그 포맷을 쓰는것이 유행이다.
	- 자바에서 log4j로는 안되고, [이렇게](https://bcho.tistory.com/m/1313)  사용하는 것이 좋다
	- 그라파나를 통해 플 시각화를 수행할 수 있다.
		- 개인정보같은거 로그에 포함되는 순간 신나게 된다.
	- DLP라는 ML API가 있어, 텍스트 정보를 스캔하여 개인정보를 탐지하는 어플리케이션들이 있다.
		- 이거랑 로그를 연결해서, 처리할 수 있다.
- 로그 들어오면, 이걸 저장한 후 DLP로 넘겨 개인정보 들어왔는지 판단한다.
	- 대시보드로는 개인정보가 제거되었는 데이터를 보내게 된다.
		- 데이터가 계속 바뀌도록 조치해야 한다.

