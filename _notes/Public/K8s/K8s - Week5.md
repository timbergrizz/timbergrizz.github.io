---
title: K8s - Week5
feed: hide
---

## Best Practices
- 구글 클라우드 기준인데, 다른 클라우드에도 유사한 기능이 있다.
- 여러 존에 걸쳐 배포할 수 있어야 한다.
	- 하나의 존에 풀을 몰빵하시면 안된다. 카카오!
- VPC-native Cluster
	- Cluster IP를 쓰는데, 이걸 써서 ip를 설정하곤 한다.
	- 쿠버네티스 IP 쓰는게 아니라 cloud vpc 부르도록 한다.
		- pod 부르는게 자연스러워진다.
	- 이 구조를 사용하지 않으면 NAT를 설치해야 하기 때문에 네트워크 구조가 복잡해질 수 있다.
	- 클러스터 크게 배포하면, 노드 수가 30만개까지 될 수 있다.
		- VPC 개수가 모자라질 수 있다.
- Node Auto-scaling
	- 당연히 해야 하는 것이다.
- Auto-upgrade / Auto-repair
	- repair는 pod 죽으면 다시 살려주는거다
	- upgrade는 dependency 같은거 꼬일 수 있다.
		- 운영을 할 때 항상 최신버전으로 운영하는 것이 좋은 것은 아닏
- Node의 OS도 굉장히 중요하다.
	- 보안적인 면도 굉장히 중요하고, 그래서 Node의 이미지를 잘 고를 수 있어야 한다.
	- COS라는 쿠베 전용 런타임 이미지를 만들었다.
		- 컨테이너 런타임에 최적화 / 자동 보안 패치 등이 이루어져 있다.
		- 특정 feature등에 대비해 ubuntu도 발생한다고 할 수 있다.
- node os를 최대한 가볍게 가져하고, shared file access를 쿠베 밖에 설계해 두는 것이 좋다.
	- 복잡도를 낮추기 위해서 밖에 두는 것이 좋다.
- Container image를 repo에 배포하면, 다운로드가 이루어진다.
	- 로컬에서 압축을 풀고, 캐싱이 되면 컨테이너가 작동하게 된다.
	- container의 start up time이 중요하고, 이를 위한 여러가지 테크닉이 있다.
		- node image 구울 때 캐싱을 박아놓고 굽는다.
	- 이러한 시나리오는 ML 모델이 큰 경우 발생할 수 있다.
	- 구글 클라우드는 image streaming 테크닉으로 repo에서 로컬에 캐싱된 이미지를 보고 fuse로 이미지를 읽어오면서 올린다.
		- 레이어 순서대로 읽어 오면서 올리고, 그래서 빠르게 작동한다.
	- 이거 올리는 속도는 최대한 빨리 만들도록 한다.
- Load Balancer 쓸 때, 클라우드 벤더에서 제공하는거 쓰는게 좋다.
	- native 쓰는것보다 DDoS 보호 등에서 좋다.
- NodeLocal DNS Cache
	- 쿠베는 서비스 만들면 dns name이 붙는다.
	- 일반적인 구조에서는 문제가 없는데, 노드가 많아지면 신나는거다.
		- 쿼리 퍼포먼스를 못버텨낸다.
	- 이를 해결할 수 있는 방법이 local dns를 사용하는 것이다.
		- 이를 통해 부담을 덜 수 있긴 한데, 좋은 방법은 아니다.
		- 클라우드 DNS에 integration을 이루는게 더 좋다.
- IP Address 배치하는거
	- 구글은 노드마다 256개까지 배치하도록 된다.
	- 큰 회사에서 IP 주소 부족한거지, 프로젝트에서는 이거 신경 쓸 필요 없다.
- 모니터링 로깅은 다세요...
- Ingress / Service 당연히 써야 한다.
- container-native LB
	- 쿠버네티스 서비스에서 트래픽이 들어오면 아무 노드로나 간다.
		- pod의 주소가 안보이고, 노드로 구성되기 때문이다.
		- 노드에서 팟으로 다시 라우팅 한다.
	- NEG라는 기능을 통해 pod로 바로 라우팅 할 수 있다.
- AutoPilot
	- 노드는 자동 매니지가 안되고, vm 단위로 계약되는데, 오토파일럿은 노드로 접근까지 안된다.
	- pod단위로 사용을 계산하고,  비용적으로 메리트가 있다.
	- node 단위의 마이크로한 조정이 어렵다.
	- 오토스케일의 overload가 없어져서 좋다.
- Backup
	- 스냅샷 잘 뜨시고, yaml만 잘 유지하면 어플리케이션 이미지는 잘 유지된다.
	- stateful set들은 중요하게 백업되어야 하고, 전략 잘 가져가야 한다.

##  Kubernetes Configuartion
- 일반적인 쿠베에 대한 내용이다.
- beta 버전 쓰지 말고, Stable API Version 쓰세요.
	- 알파나 베타 버전 쓰시면 신나집니다.
	- 구조 바뀌는 경우가 만핟.
- cnfig는 명령으로 하지 말고 항상 yaml based로 만들어라.
- naked pod으로 쓰지 마라.
	- replica set이나 deployment 안묶여 있는거 쓰지 마라
- label 전략 잘 써라.
	- 여기에 버전 정보를 넣는 경우도 있다.
	- 이건 굉장히 중요한 내용이다.
- deployment 쓸 때, record 쓰면 롤백이 된다.
	- 롤백 되는거 확인해라
- latest / no tag 쓰지 마세요.
	- 그냥 가져와서 쓰는거 별로 좋지 않은 practice이다.
	- 컨테이너를 업데이트해도 리포를 모른다.
		- 태그 이름이 같기 때문에 같은 이미지로 가정한다.
	- skaffold같은 툴 써서 커버할 수 있다.
- 컨테이너 올라올 때 마다 새로운 태그 올리도록 해야한다.
	- 버전 넘버 쓰는것도 좋고, commit number 써도 좋다.
- request / limit
	- CPU등 자원 양 명시해주는게 overcommited status 피하는데 도움이 된다 .
		- 필요로 하는 자원이 가용 자원보다 큰 상황.
- Readiness랑 liveness 사용하세요

## Container Image
- 베이스 이미지 가볍게 만드는거 중요하다.
	- alphine이나 slim 붙는 이미지가 있다.
		- 이런게 가볍다.
		- 구글에서 쓰는 데비안은 더 가볍다. 베이스는 이런거 써라.
	- security hazard 없는 것 사용해야 한다.
		- security를 보장할 수 있는거 써야 한다.
	- 무조건 official image 사용해라.
- Jib같은 걸 이용해서 jar integration하는 것이 좋다.
- 이미지의 점 문제 찾아주는 솔루션 있다. [sysdig](https://sysdig.com/blog/docker-image-scanning/](https://sysdig.com/blog/docker-image-scanning/))
	- 스캐닝의 기준이 리눅스 os 레벨의 문제고,  어플리케이션이나 미들웨어 단의 문제는 스캔이 안된다.
	- 툴을 돌리면 취약점이 엄청나게 나올 것이다.
		- 도커 이미지 업그레이드 속도가 느리기 때문에, 엄청나게 나올 것이고 다 잡을 수 없을 것이다.
			- critical만 꼭 잡도록 하면 된다.
- binary authorization은 쿠번네티스 기능이다.
	- signing 안 된 이미지는 배포를 할 수 없도록 하고, 배포하려면 인증을 받아야 한다.
		- 검증된 이미지만 배포할 수 있도록 하는 것이다.
	- DevOps에서 굉장히 중요한 기능이다.
- 검증된 보안 이미지에 대한 가이던스를 갖고 있어, 좋다.

## Workload
- 어플리케이션에서 필수적으로 해야 하는 것
	- liveness / probe 만들어 줘야 한다.
- logging은 json으로 하는 것이 좋다.
	- 로그 파싱하기도 좋고 분석하기도 좋다.
	- 에러 메시지만 보는것이 아니라, 데이터 파이프라인에도 사용되어서 형식 맞춰주는게 좋다.
- cloud code 곡 써라...

## Cost Optimization
- usage metering
	- 보통은 vm 단위로 측정되는데, SaaS 만들면 어떻게 측정할거임?
		- 포드 단위로 측정할 수 있어야 한다.
	- 구글의 경우 expose하면 빅쿼리로 들어간다.
		- sql query로 분석한다.
- cost optimization은 사용량을 볼 수 있고, 이를 바탕으로 사용량을 최적화할 수 있다.
- VM 타입 잘 골라야 한다.
	- E2가 N1보다 30% 싸다.
		- CPU 클럭 차이 나서 니즈 확인하고 필요에 따라 사용하도록 할 수 있어야 한다.
	- PVM
		- 연속 기능으로, 가용 보장 없이 저렴하게 사용할 수 있는 것들이 있다.
		- API 서버는 이렇게 쓰면 가격 절약할 수 있어서 좋다.
		- ML은 비용을 50%까지 줄일 수 있다.
			- 이거 체크포인트 만들어서 죽어도 다시 시작할 수 있도록 하면 된다.

## Security
- 컨테이너 루트 파일시스템은 readonly로
- 루트로 작동시키지 마라
- 권한 상승 쓰지 마라.
	- 근데 이거 어플리케이션 동작 안할수도 있어서 추천하지 않는다.
	- 시스템 콜 타고 들어가서, 이것때문에 문제 생길 수 있다.
- 네트워크 정책 쓰면 좋은데 의무적이지는 않다.
	- VPC 방화벽 쓰면 쿠버네티스 자체 방화벽 필요 없어진다.
- node에서 직접 접근 못하게 막아야 한다.
- gVisor같은 커널 보안 솔루션 쓰면 좋은데, 이건 엔터프라이즈급
- Authorised Network
	- Kubectl 마음대로 못하게 하는 것
- private cluster를 사용한다.
	- node를 expose시키는거 나쁜 practice
- GKE는 자동으로 master ip 바꿔주는 기능 있다.
	- 원치 않는 시스템 셧다운 발생할 수 있다.
	- credential 바뀌는 기능도 발생할 수 있다.
- 방화벽 써라.

## 대형 서비스 아키텍처
- API 서버 / Redis 붙인다.
	- 데이터 타입을 많이 지원해서 redis 많이 쓴다.
- 이후 RDB랑 mongo 단다.
	- 근데 mongo는 scalibility가 별로다.
	- 카산드라나 DynamoDB, BigTable, ScyllaDB같은걸 키밸류 저장용으로 많이 쓴다.
	- nosql 운영이 매우 어렵고, 벤더 솔루션이나 매니지드 솔루션 사용한다.
		- 직접 설치해서 구성하는건 부담이 크다.
- 파일 시스템은 로컬 쓰는건 문제 없고, 공유 파일 시스템 사용하는 것이 문제가 된다.
	- API 서버는 로드밸런싱이 된다.
	- MSA이 경우 L7 스위치로 LB 쓴다.
- 파일 공유하기 위해서 NFS 사용한다.
	- 소프트웨어의 경우는 속도가 안나와서 하드웨어로 쓰거나, GFS같은거 쓴다.
	- Blob Storage (S3, GCS) 쓰는데, 스케일링에는 좋은데 성능이 구리다.
		- 성능 필요한걸 NFS로 보낸다.
- API 콜 들어오면 인증을 해야한다.
	- 인증하는 시스템을 IDM (Identity Management System)이라 한다.
	- OAuth Provider 많이 사용하고, DB로도 많이 사용한다.
	- 이 시스템 설계가 많이 망가진다.
		- 중앙 집중화된 시스템을 만들어야 하는데 그룹 설계 잘못하는 경우가 많다.
		- ID시스템 통합 안되고 여러개 있는 경우가 많다.
		- 사용자가 중복적으로 로그인을 해야하는 상황이 발생하게 된다.
	- 다른 시스템과 협업할 수 있는 시스템을 구성할 수 있어야 한다.
		- [WSO2 identity Service]([https://wso2.com/identity-server/](https://wso2.com/identity-server/)) 찾아보면 좋다.
			- 근데 production service에는 좀 애매하다.
- 요즘은 API Gateway도 사용한다.
	- 여기에 CDN만 서빙하면 완성이다.
	- 이게 백엔드 시스템이다.
- 여기에 대한 인프라가 필요하다.
	- BareMetal, VM, K8s를 사용해 적용시킬 수 있다.
	- 각각의 용도가 다르게 된다.
		- 보안 필요한 경우 baremetal 필요하다.
		- vm도 편한데, 요즘은 k8s로 많이 가는 편이다. 
	- 추가로, 서드 파티 매니지 서비스를 사용한다.
		- Datadog, RedisLabs 등을 사용할 수 있다.
- 이 뒤에  Operating System 붙인다.
	- CI/CD (젠킨스 / argocd가 스탠다드)
	- Logging(ELK)
	- Monitoring(Promethus + Grafana)
		- 이거 클러스터링이 안되서, 그냥 서드파티로 많이 뺀다.
		- 클라우드 서비스 많이 쓰게 된다.
			- datadog, newrelic 좋은데 조온나 비싸다.
- 여기서 데이터를 뽑아오자.
	- 뽑은 데이터를 데이터 웨어하우스 / 데이터 레이크로 보낸다.
	- 빅데이터 분석 시스템이 된다.
- 백엔드로부터 데이터를 가져오는 것을 ETL (Extract Transformation and Loading)이라 한다.
- 예전에는 소스가 RDBMS, FTP였는데, 요즘은 SaaS가 데이터 소스가 된다.
	- 모던 툴들은 SaaS에 집중하게 된다.
	- 하둡, 스파크도 포함한다.
- 이렇게 데이터를 가져오는 것을 Ingestion이라 한다.
- Data Warehouse / DataLake 시스템을 만든다.
	- Oracle Exadata가 강하다
		- 정형 데이터만 된다.
	- 빅데이터 시대가 되면서 비정형 데이터가 발생했고, 엄청나게 많은 데이터가 발생했다.
		- 하둡과 스파크가 주로 사용되게 된다.
- data warehouse는 저장을 한 후, 추가적인 데이터 웨어하우스를 만들어 비즈니스에서 필요한 데이터만 가져오도록 한다.
	- data mart라 하고, 이를 warehouse와 계속 연결하도록 한다.
	- mart에 대한 대시보드가 필요하고, 이를 Business Intelligence 솔루션으로 처리한다.
		- tableu, Looker, power BI가 주로 사용된다.
- warehouse나 lake는 분석하는 데이터 분석 팀을 필요로 한다.
	- 세일즈 팀은 분석팀으로 요청해서 받아와야 한다.
	- 그리고 분석 팀은 도메인 지식이 부족해서 bottleneck이 되게 된다.
	- 데이터 분석팀은 회사의 공유 팀이고, 돈을 버는 조직이 아니다.
		- 투자 자원에 한계가 있다.
	- 각각의 부서 별로 데이터 엔지니어링 팀을 넣어버리도록 하는 것이다.
		- 예산에 대한 부담이 줄고, 전문성이 올라간다.
		- 다른 팀의 정보를 필요로 할 때, ETL을 또 해야 해서 중앙 집중화 시켜야 한다는 얘기가 나온다.
			- 예전에는 카피를 해왔어야 했는데, 요즘은 federation이라고 remote로 쿼리 같이 때릴 수 있도록 할 수 있다.
			- 팀을 이렇게 운영해도 전체 팀을 snowflake에 구성하도록 할 수 있는 것이다.
	- 데이터를 API로 뽑도록 한다.
		- 이를 DaaS 서비스라고 한다.
			- 기업은 갖고 있는 데이터가 어딨는지를 모른다.
- 다음 단계로 데이터 거버넌스 / 데이터 카탈로그가 된다.
	- 데이터의 정보가 카탈로그로 등록이 된다.
		- table / column의 description을 가져오도록 할 수 있다.
	- 구글 빅데이터 시스템의 plx같은 시스템을 통해 DB를 고르고,  정보들을 모두 가져올 수 있도록 할 수 있게 되는 것이다.
- 원하는 데이터를 원하는 순간에 볼 수 있도록 하는 것이 데이터 분석의 핵심이다.
- Access Control도 중요하다.
	- 흩어져 있는 DB의 column, table 단위로 접근 관리를 할 수 있도록 할 수 있어야 한다.
- ETL을 통해서 데이터가 이동을 하는데, 이러한 이동 흐름을 볼 수 있어야 한다.
	- 데이터의 이동을 확인하는 것을 Data Lineage라 한다.
		- 어느 테이블에서 어느 테이블로 이동했는지 기록들을 모두 확인할 수 있도록 한다.
- 중앙 집중형에서 분산화, 셀프 서비스화가 트렌드라고 할 수 있다.
	- 요즘은 SQL만 쓰면 비즈니스 하는 사람들도 빅 데이터를 분석을 할 수 있도록 하는 것이다.
	- 구글 시트 연결해서 엑셀로도 할 수 있도록 쉬워지고 있는 것이다.
		- 진입 장벽이 낮아지고, 누구나 할 수 있는 쪽으로 움직이는 것이다.
- 관련 글은 이거 한번 읽어보면 된다. [분산형 데이터 분석 아키텍처-데이터 매쉬](https://bcho.tistory.com/1379)
- 구현 구조가 어떻게 구성되는지랑은 조금은 다른 얘기가 된다.
- 데이터 레이크에서 슈퍼 컴퓨터 등이 필요로 하는 순간들이 있다.
	- DNA 시퀀싱같은게 그렇게 발생한다.

- 이제 API / Big Data에서 오는 데이터로 훈련 데이터를 사용하는 것이다.
	- 이를 통해 모델을 만들고, 이걸 다시 API로 집어 넣는 것이다.
	- 모델을 다시 외부로 서빙하도록 하는 것이다.
- API - 모델로 이루어지는 서빙 구조를 ML System이라 한다.
	- FDS (이상 탐지) 등에서 주로 사용되게 된다.
	- 마케팅 여부 등을 줄 수 있는 판단 모델도 생기고 있다.
- lifetime 모델이라고, 90일동안 얼마나 사용할지를 고려하는 문제도 있다.
	- 이를 바탕으로 타겟팅 마케팅을 한다.
	- 산업마다 타겟팅이 달라지게 된다.
- ML 시스템은 신나게 복잡하다.

