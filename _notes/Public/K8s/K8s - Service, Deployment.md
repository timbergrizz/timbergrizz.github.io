---
title: K8s - Service, Deployment
feed: hide
---
## Deployment
### Deployment strategy
- 전략이 존재한다.
	- 하드웨어를 돌리고 있을 때, 새로운 버전을 배포할 때 이를 지운 후, 새 포드를 한번에 올린다.
	- recreate할 땐 순간적으로 다 내려가서 서비스가 정지된다.
- 그래서 롤링 업데이트라는 전략을 사용한다.
	- 여러개의 하드웨어를 돌릴때 순차적으로 하나씩 바꿔 끼우는 전략이다.
	- 서비스 중단은 발생하지 않지만, 동시에 두가지 버전이 존재할 수 있어 트래픽이 섞여 들어갈 수 있다.
- 블루&그린 배포나 카나리 배포는 지원 안된다.
	- 블루 / 그린 배포는 동시에 여러개를 띄우고, 트래픽의 레이블을 바꿔 틀어버린다.
		- 트래픽이 잠깐 끊기지만 버전을 유지할 수 있다.
		- deployment를 두개 만들고, selector로 순간적으로 바꾸도록 하는 것이다.
	- 카나리 배포는 새 버전까지 추가해서 테스트하면서 트래픽에 문제가 없는지 확인한 후, 새 버전으로 밀어버리는 전략이다.
		- 테스트 용도로 사용되는 전략이다.
		- 이것도 새롭게 deployment 올리고 selector 같이 물려서 가능하도록 한다.
- 쿠버네티스에는 istio라는 플러그인이 있고, 여기에는 프록시라는 개념이 있다.
	- 쿠버네티스에 가상 네트워크 레이어를 만들어 여러가지 배포 전략도 채용할 수 있다.
	- 멀티 쿠버네티스를 지원해서, 엔드 포인트로 트래픽이 들어오면 멀티 쿠버네티스로 카나리 배포 등을 할 수 있다.
- deployment는 롤링 업데이트 기능이 있다.
	- 배포 잘못되었을때 복구 할 수 있다는 점이 장점이다.

## Service
- 서비스는 자동으로 DNS 이름이 할당된다.
	- 쿠버네티스 자원 ip 계속 바뀌어서 정적으로 호출할 수 있는 엔드 포인트가 없다.
	- 따라서 DNS 서비스로 이름이 등록된다.
		- {서비스명}.{네임스페이스 이름}.svc.cluster.local 형태로 만들어진다.
	- 밖에서는 안보인다.
		- external ip 주소 할당해서 사용할 수 있다.
			- 이 ip를 사용해 쿠베 서비스에 갖다 붙일 수 있다.
- 서비스를 만들 때, 하나의 서비스에 멀티 포트를 부여할 수 있다.
	- 사용 포트로 트래픽을 받아 타겟 포트로 포워딩 한다.
	- 여러개의 ip 포워딩 룰을 만들 수 있다.
- 이때 session appinity를 설정할 수 있다.
	- 라운드 로빈은 순차적으로 트래픽을 배포한다.
	- 이 반대 방식이 세션 어피니티다.
		- 일종의 해쉬값을 사용하는 방식으로, 클라우드 ip 해쉬값 보고 같은걸로 보낸다.
		- 클라우드가 다른 포드로 붙을 수 있는데, 이러면 같은 클라우드는 같은 서버로 붙는다.
		- 세션을 유지하고 shared 메모리로 써도 좋지만, 복잡하지 않을 땐 이렇게 사용하는 것이 좋다.
		- 같은 유저는 같은 부분을 조회할 확률이 높아, 캐시의 hit을 높이기 위해서도 사용할 수 있다.
	- 아니면 external ip를 지정할 수 있다.

- 서비스는 여러개의 타입이 존재한다.
###  ClusterIP
- 생성하면 이게 기본이다.
### Load Balancer
- VPC가 있고 내부에 쿠베가 있을 때, 클러스터 ip를 만들면 클러스터 ip로 만든 쿠베는 프라이빗 ip로만 접속할 수 있다.
	- 쿠베 외부에서 접속이 안된다.
	- 로드밸런서로 가면 로드밸런서가 public ip를 갖고, 따랴서 vpc에서 접속이 가능해진다.
	- 인터넷에도 접속이 가능해진다.
		- 이게 표준 로드밸런서이다.
- 클라우드 벤더들 보면 internal ip 쓰는 로드밸런서 있다.
	- 이건 VPC IP를 쓰는 것이다.
		- VPC 내부에선 접근 가능하지만, 외부에서는 접근할 수 없다.
- 접근 가능한 ip 대역을 클러스터 ip, vpc ip, 공용 ip 3가지로 나누어 생각해주어야 한다.
- 구글 같은 경우 VPC Native IP라는 모드가 있다.
	- 이렇게 클러스터를 생성하면 VPC 내부에 쿠버네티스가 생성되었을 때 쿠버네티스 ip가 vpc ip 대역을 사용하게 된다.
		- vpc 내부에서 쿠버로, 쿠버에서 vpc로 호출이 가능하다.
	- vpc native로 사용하지 않은 경우 쿠버네티스가 있을 때, 서비스를 통해서만 볼 수 있다.
		- NAT를 설치하여 확인할 수 있다.
	- 쿠베는 집적도가 되게 높아서 pod를 많이 띄우고, ip를 많이 소모하게 된다.
- External Name이라는 타입이 있다.
	- 외부의 IP로 연결해준다.
		- 코딩할 때 테스트를 위해 하드 코딩으로 부르게 만들 수 있고, 이럴 때 external name 사용한다.
### NordPort
- 실제 노드가 public port를 열어 여기서 라우팅을 한다.
- 실제 로드 밸런서를 사용할 수 없을 때 사용한다.
- 권장하지 않는 방법이다.
	- 노드가 public ip를 갖고 외부로 노출되고, 따라서 보안적으로 좋지 않다.
	- 웬만하면 로드밸런서 통해서만 트래픽 받도록 설계해야 한다.

### Headless Service
- 호출을 할 수 없는 서비스이다.
- nslookup보면 연결된 서비스들 나온다.
	- headless 서비스에 사용하는 서비스 바인딩 해놓으면, 연결되어 있는 pod 정보를 확인할 수 있다.
- hashicop consul등이 자주 사용되는 서비스이다.
	- 이러한 것들이 서비스 디스커버리 메커니즘이다.

## Probes
- Liveness Probes
	- 서비스가 죽었는지 확인한다.
		- 죽은 것 같으면 kubelet이 재시작시킨다.
- readiness probe
	- 서비스 올리고 응답 안되면 서비스 리스트에서 빼고 올라올때까지 기다려준다.
	- 응답 오면, 서비스의 로드 밸런서에 넣는다.
- 이러한 probe를 구현하기 위해 http를 가장 자주 사용하고, ssh도 사용은 한다.
	- http가 멀쩡히 오면 정상 작동하고, 아니면 죽은걸로 치는 것이다.
	- 아니면 shell script 사용할 수 있다.
		- healthy 파일 있으면 멀쩡한걸로, 아니면 죽은걸로 생각하는 것이다.
		- heartbeat를 몇초부터 확인할 것인지, 몇초 단위로 확인할 것인지도 올려야 한다.
- 이외에도 여러가지 probe 기법들이 존재한다.
	- timeoutSeconds는 몇초 안에 답변 안우면 죽은것으로 판단할 것인지 결정한다.
	- failureThreshold는 몇번 답변 제대로 안오면 죽은것으로 판단할 것인지 결정한다.
- 따로 디렉토리 만들어서 healthy check policy 만들 수 있다.
	- pod들을 만들어서 앞에 서비스를 여러개 붙였다고 하자.
		- ip가 다를 것인데, 어떻게 처리할 것인가?
			- 새롭게 엔드포인트를 하나 더 묶어주는데 이렇게 수행하는 것이 ingress이다. 일종의 로드 밸런서이다.
			- 밖을 묶는 로드밸런서는 ALB / 안을 묶는 로드밸런서는 ELB로 찍힌다.
		- 서비스를 구성하게 되면 Ingress를 붙여 엔드 포인트를 뽑아주어야 한다.
- Ingress는 L7 로드밸런서인데, HTTP이므로 HTTPS로도 커뮤니케이션을 할 수 있다.
