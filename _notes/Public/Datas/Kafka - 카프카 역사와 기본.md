---
title: Kafka - 카프카 역사와 기본
feed: hide
---

## 역사
- 링크드인에서 소스 어플리케이션과 타겟 어플리케이션을 연결해야 했고, 개수가 많아져 어려워지게 되었다.
	- 하나만 있을때는 괜찮은데, 어플의 타겟과 소스가 많아지면 어떻게 처리할 것인가?
	- 이거 구성하다가 하나에 장애 나면, 여러개에 동시에 장애 날 수 있는거다.
		- 이를 방지하기 위해 상용 데이터 프레임워크 / 오픈 소스를 아키텍처에 사용하여 파이프라인의 파편화를 개선하고자 했다.
		- 복잡한 파이프라인으로 만들고, 장애 범위를 단순화하고자 했으나 이러한 시도가 실패로 돌아갔다.
			- 결과적으로 카프카가 만들어졌다.
				- 중앙에 로그가 형성되는 구조를 갖게 된다.
					- 모든 데이터를 한 곳에 모아 처리할 수 있도록 중앙집중화 하였다.
				- 링크드인의 내부 데이터 흐름을 개선하기 위해서 만들어졌다.

## 기본 구조
- 카프카는 다음과 같이 구성된다.
	- 토픽이라는 개념이 제시된다.
		- RDBMS의 테이블과 같은 개념이다.
			- student, teacher와 같이 구분하고자 하는 데이터의 구분에 따라 토픽을 새로 만들고, 구분하게 된다.
		- 한 개 이상의 파티션을 가지게 된다.
			- 토픽을 만들면, 파티션이 하나인 토픽을 만들 수도 있고, 여러개의 토픽을 가진 파티션도 만들 수 있다.
			- 이렇게 만들어진 토픽을 기준으로 데이터를 보낼 수 있게 된다.
	- 데이터는 프로듀서가 보내게 된다.
		- 프로듀서는 파티션으로 데이터를 태운다.
		- 특정 메시지에 대해서 데이터를 하나 보내게 되면, 파티션 중 하나에 들어가게 된다.
			- 모두에 들어가는거 아니다.
		- 파티션의 내부 구조는 큐의 내부 구조와 동일하다.
			- 한 줄로 이루어진 큐 구조에서 컨슈머가 데이터를 풀링하는 방식으로 작동하게 된다.
			- 가장 첫번째 들어왔던 데이터부터 차례대로 가져가게 된다.
		- 순차적으로 오래된 데이터부터 최신 데이터까지 큐처럼 가져갈 수 있게 된다.
	- 컨슈머는 여러 파티션의 데이터를 가져가 데이터를 구성하게 된다.
	- 전체적인 구조는 큐 자료구조와 유사하지만, 컨슈머가 적재된 데이터를 풀링한다는 점이 다르다.
		- 그러나 파티션의 데이터는 삭제되지 않는다.
			- 카프카에서 가장 큰 특징을 가지게 된다.
		- 특정 컨슈머가 어떤 데이터까지 읽었는지 기록하게 된다.
			- 커밋이 이를 기록하고, 커밋을 통해 어디서부터 읽어야할지 알 수 있게 된다.

## 데이터 파이프라인으로 적합한 이유
1. 높은 처리량
	- 카프카는 프로듀서가 브로커로부터 데이터를 수신할 때, 컨슈머가 브로커로부터 데이터를 받을 때 묶어서 전송한다.
		- 동일한 양의 데이터를 보낼 때 네트워크 통신 횟수를 줄일 수 있으면 동일 시간 내에 더 많은 데이터를 전송할 수 있다.
		- 많은 양의 데이터를 배치로 묶어서 처리할 수 있고, 따라서 대용량 로그 데이터 처리에 적합하다.
	- 파티션 단위를 통해 동일 목적의 데이터를 여러 파티션에 분배하고 병렬 처리할 수 있다.
		- 파티션이 토픽 내부에 한 개 이상 존재하고, 파티션 하나당 컨슈머 하나를 붙일 수 있다.
			- 컨슈머의 데이터 처리량이 초당 1개일 경우 컨슈머를 늘려 처리하도록 할 수 있다.
				- 데이터 처리의 스케일 아웃을 가능하도록 할 수 있다.
		- 파티션을 늘리 linear한 데이터 처리량을 늘릴 수 있다.
	- 시간당 데이터 처리량을 늘릴 수 있다.
2. 확장성
	- 데이터의 들어오는 양을 예측하기 어렵다.
		- 데이터의 입력 량이 달라지는 가변적인 환경에서 안정적으로 확장할 수 있도록 설계되었다.
		- 데이터 입력이 증가하면 클러스터의 브로커 개수 늘려 스케일 아웃, 데이터 입력 감소하고 서버 더 필요 없어지면 브로커 개수 줄여 스케일인 할 수 있다.
			- 클라우드 네이티브에서 작동시키는 스케일 인 - 아웃 기능이다.
		- 이 과정에서 무중단으로 클러스터를 운영할 수 있다는 점이 장점이다.
3. 영속성
	- 데이터를 생성한 프로그램이 종료되더라도 사라지지 않는다.
	- 카프카는 전송받은 데이터를 메모리에 쓰는 것이 아닌, 파일 시스템에 저장한다.
		- 이거 느리다고 생각할 수 있는데, OS 레벨에서 파일 시스템 최대한 활용하여 속도를 증가시킨다.
			- 한번 읽은 파일 내용은 메모리에 저장시켰다가 다시 사용하는 방식으로 작동시킬 수 있다.
	- 브로커가 갑자기 죽어도 파일 시스템에 데이터가 저장되어 있기 때문에 이를 복구시켜 다시 작동시킬 수 있다.
4. 고가용성
	- 일반적으로 브로커 3대로 구성되고, 일부 서버에 문제가 발생해도 무중단으로 안전하고 지속적으로 데이터를 처리할 수 있다.
		- 프로듀서에서 데이터를 보냈을 때 메시지는 한개에 저장되는 것이 아니라, 여러개의 브로커에 복제하여 저장되게 된다.
		- 한개의 브로커에 장애가 발생하더라도 나머지 브로커가 남아있어 지속적으로 처리할 수 있도록 한다.
	- 컨슈머는 기존의 데이터를 가져가는 것이 아니라 남아있는 데이터를 바탕으로 가져갈 수 있도록 한다.
		- 지속적으로 데이터를 가져갈 수 있도록 한다.
	- 온 프레미스 서버랙이나 클라우드에서도 복제할 수 있는 환경을 제공한다.

## 빅 데이터 아키텍처의 종류와 카프카의 미래

### 초기 빅데이터 플랫폼 - 데이터 레이크
- 기존에는 원천 데이터 / 파생 데이터 / 서빙 데이터로 나누어져 있었다.
	- 원천 데이터는 소스로부터 받은 최초의 데이터라고 할 수 있다.
	- 원천 데이터를 프로세싱하여 만들어진 데이터를 파생 데이터라 한다.
	- 파생 데이터를 바탕으로 사용할 수 있도록 서빙 데이터로 만들어 저장되었다.
- 각 서비스에서 엔드 투 엔드로 데이터를 배치로 모으고, 이렇게 데이터 파이프라인을 운영해야 했다.
	- 유연하지 못하고, 실시간으로 생성되는 데이터의 인사이트를 서비스 어플리케이션에 빠르게 반영할 수 없었다.
	- 데이터의 히스토리를 파악하기 어려웠기 때문에, 데이터가 파편화되면서 데이터 정책을 지키기 어려웠다.

### 람다 아키텍처
- 크게 세가지 레이어로 이루어져 있다.
	- 배치 레이어
		- 배치 데이터를 모아 특정 시간마다 일괄 처리한다.
	- 서빙 레이어
		- 배치 레이어와 스피드 레이어에서 만들어진 데이터를 제공하도록 하는 레이어가 서빙 레이어이다.
	- 스피드 레이어
		- 서비스에서 생성되는 원천 데이터를 실시간으로 빠르게 분석하는 용도로 사용된다.
		- 이러한 스피드 레이어에 카프카가 위치하게 된다.
- 한계가 존재한다.
	- 데이터를 배치 처리하는 레이어와 실시간 처리하는 레이어가 분리되어 있다.
		- 분석 / 처리하는데 필요한 로직이 2벌로 각각의 레이어에 따로 존재해야 한다.
		- 배치 데이터와 실시간 데이터를 융합하여 처리할 때 유연하지 못하다.
			- 파편화가 발생하게 된다.
	- 1개의 로직을 추상화하여 배치 레이어와 스피드 레이어에 동일한 로직을 적용하는 방법이 제시되었다.
		- 서밍버드라는 오픈소스가 있긴 했는데, 해결되지는 않았다.
			- 어쨌거나 두 레이어가 따로 관리되기 때문에 그렇다.
			- 디버깅 / 테스트가 따로 이루어지게 되기 때문이다.

### 카파 아키텍처
- 스피드 레이어와 서빙 레이어로 구성된다.
	- 배치 레이어를 제거했다.
- 디버깅 / 배포의 파편화를 제거하기 위해 노력했다.
	- 모든 데이터를 스피드 레이어에서 처리하려고 하는 노력이 카파 아키텍처의 핵심이다.
- 스피드 레이어에서 일괄적으로 데이터를 처리하고, 서빙 레이어에 적합한 형태로 데이터를 보낼 수 있다는 것이 원칙이다.
	- 카프카를 활용해 이를 달성할 수 있다는 것이 가장 큰 특징이라고 할 수 있다.
		- 배치 데이터와 스트림 데이터를 모두 모으는 형태로 활용할 수 있어야 한다.
	- 이렇게 하기 위해 데이터를 배치 형태로 만들 수 있어야 한다.
		- 레코드 메시지 단위가 처음 / 가장 마지막 레코드 단위로 이루어져 있다.
			- 파티션에는 데이터가 순차적인 큐 모양으로 적재된다.
		- 스트림 데이터를 배치로 나타낼 수 있으면, 람다 아키텍처의 배치 레이어가 필요 없게 된다.
			- 스트림으로 들어온 데이터에서 배치 형태로 데이터 스냅샷을 확인하고, 이 데이터를 기반으로 배치 데이터 처리를 한다.
			- 변환 기록 로그를 남겨 배치 데이터를 기반으로 스트림 데이터와 배치 데이터를 함께 운영할 수 있게 된다.
- 로그 기반으로 데이터를 사용하고, 배치 데이터를 활용하기 위해서는 반드시 타임스탬프가 기록되어야 한다.
	- 카프카에서는 데이터 하나하나당 타임스탬프가 기록되고, 이 데이터를 기반으로 특정 기간의 데이터를 하나로 묶어 배치로 처리하게 된다.

### 배치 데이터 vs 스트림 데이터
- 배치 데이터
	- 한정된 데이터 처리를 수행한다.
	- 대규모 배치 데이터를 위해 일반적으로 분산 처리를 수행한다.
	- 분 / 시간 / 일 등으로 시간을 설정하고, 이를 묶어서 처리하기 위한 지연이 발생한다.
		- 복잡한 키의 조인을 수행하는 등의 활용도가 있다.
- 스트림 데이터
	- 단순한 키 조인만 수행하면서, 분 단위 이하의 지연만 발생한다.
	- 지속적으로 들어오는 데이터를 분산 처리로 처리하고, 무한한 데이터를 처리하게 된다.

### 스트림 데이터를 배치로 사용하는 법
- 구체화된 뷰를 활용하는 방식을 통해 사용할 수 있다.
- 특정 일시로 데이터를 뷰 형태로 가져와, 한 번의 배치처럼 사용한다.
	- key-value 스토어나 큰 용량의 데이터를 분산 처리할 수 있다.
- 로그(레코드)에 시간을 남기기 때문에 이러한 방법을 사용할 수 있다.

## 스트리밍 데이터 레이크
- 카파 아키텍처와 별개로 볼 수 있다.
	- 얘는 서빙 레이어까지 날아갔다.
	- 카프카가 배치 데이터도 처리하고, 서빙 데이터도 처리할 수 있댜!
- 스트림 레이어로 사용되는 카프카의 데이터 분석과 프로세싱을 오랜 기간 저장할 수 있고 사용할 수 있다면 필요 없지 않을까?
	- 카프카를 브로커로 사용하고, 자주 사용하는 데이터와 자주 사용하지 않는 데이터로 구분하는 등의 문제가 발생한다.
- 모든 데이터 아키텍처를 카프카로 통합한 미래는 이렇게 되지 않을까에 대한 예상이다.
- 이를 달성하기 위해서 여러가지 개선을 진행하고 있다.
	- 자주 접근하는 데이터와 자주 접근하지 않는 데이터를 분리하는 방식을 개발하는 점이다.
	- 브로커 어플리케이션이 인스턴스, 메모리에 점유하고 있는 것이 아닌 대용량의 오브젝트 스토리지로 저장하도록 한다.
		- 자주 사용하는 데이터는 메모리와 디스크, 자주 사용하지 않는 데이터는 오브젝트 스토리지에 할당하도록 하면 된다.
	- 이를 통해 더 많은 데이터를 카프카에서 운용할 수 있을 것이다. 타겟 어플리케이션을 연결해야 했고, 개수가 많아져 어려워지게 되었다.
	- 하나만 있을때는 괜찮은데, 어플의 타겟과 소스가 많아지면 어떻게 처리할 것인가?
	- 이거 구성하다가 하나에 장애 나면, 여러개에 동시에 장애 날 수 있는거다.
		- 이를 방지하기 위해 상용 데이터 프레임워크 / 오픈 소스를 아키텍처에 사용하여 파이프라인의 파편화를 개선하고자 했다.
		- 복잡한 파이프라인으로 만들고, 장애 범위를 단순화하고자 했으나 이러한 시도가 실패로 돌아갔다.
			- 결과적으로 카프카가 만들어졌다.
				- 중앙에 로그가 형성되는 구조를 갖게 된다.
					- 모든 데이터를 한 곳에 모아 처리할 수 있도록 중앙집중화 하였다.
				- 링크드인의 내부 데이터 흐름을 개선하기 위해서 만들어졌다.

## 기본 구조
- 카프카는 다음과 같이 구성된다.
	- 토픽이라는 개념이 제시된다.
		- RDBMS의 테이블과 같은 개념이다.
			- student, teacher와 같이 구분하고자 하는 데이터의 구분에 따라 토픽을 새로 만들고, 구분하게 된다.
		- 한 개 이상의 파티션을 가지게 된다.
			- 토픽을 만들면, 파티션이 하나인 토픽을 만들 수도 있고, 여러개의 토픽을 가진 파티션도 만들 수 있다.
			- 이렇게 만들어진 토픽을 기준으로 데이터를 보낼 수 있게 된다.
	- 데이터는 프로듀서가 보내게 된다.
		- 프로듀서는 파티션으로 데이터를 태운다.
		- 특정 메시지에 대해서 데이터를 하나 보내게 되면, 파티션 중 하나에 들어가게 된다.
			- 모두에 들어가는거 아니다.
		- 파티션의 내부 구조는 큐의 내부 구조와 동일하다.
			- 한 줄로 이루어진 큐 구조에서 컨슈머가 데이터를 풀링하는 방식으로 작동하게 된다.
			- 가장 첫번째 들어왔던 데이터부터 차례대로 가져가게 된다.
		- 순차적으로 오래된 데이터부터 최신 데이터까지 큐처럼 가져갈 수 있게 된다.
	- 컨슈머는 여러 파티션의 데이터를 가져가 데이터를 구성하게 된다.
	- 전체적인 구조는 큐 자료구조와 유사하지만, 컨슈머가 적재된 데이터를 풀링한다는 점이 다르다.
		- 그러나 파티션의 데이터는 삭제되지 않는다.
			- 카프카에서 가장 큰 특징을 가지게 된다.
		- 특정 컨슈머가 어떤 데이터까지 읽었는지 기록하게 된다.
			- 커밋이 이를 기록하고, 커밋을 통해 어디서부터 읽어야할지 알 수 있게 된다.

## 데이터 파이프라인으로 적합한 이유
1. 높은 처리량
	- 카프카는 프로듀서가 브로커로부터 데이터를 수신할 때, 컨슈머가 브로커로부터 데이터를 받을 때 묶어서 전송한다.
		- 동일한 양의 데이터를 보낼 때 네트워크 통신 횟수를 줄일 수 있으면 동일 시간 내에 더 많은 데이터를 전송할 수 있다.
		- 많은 양의 데이터를 배치로 묶어서 처리할 수 있고, 따라서 대용량 로그 데이터 처리에 적합하다.
	- 파티션 단위를 통해 동일 목적의 데이터를 여러 파티션에 분배하고 병렬 처리할 수 있다.
		- 파티션이 토픽 내부에 한 개 이상 존재하고, 파티션 하나당 컨슈머 하나를 붙일 수 있다.
			- 컨슈머의 데이터 처리량이 초당 1개일 경우 컨슈머를 늘려 처리하도록 할 수 있다.
				- 데이터 처리의 스케일 아웃을 가능하도록 할 수 있다.
		- 파티션을 늘리 linear한 데이터 처리량을 늘릴 수 있다.
	- 시간당 데이터 처리량을 늘릴 수 있다.
2. 확장성
	- 데이터의 들어오는 양을 예측하기 어렵다.
		- 데이터의 입력 량이 달라지는 가변적인 환경에서 안정적으로 확장할 수 있도록 설계되었다.
		- 데이터 입력이 증가하면 클러스터의 브로커 개수 늘려 스케일 아웃, 데이터 입력 감소하고 서버 더 필요 없어지면 브로커 개수 줄여 스케일인 할 수 있다.
			- 클라우드 네이티브에서 작동시키는 스케일 인 - 아웃 기능이다.
		- 이 과정에서 무중단으로 클러스터를 운영할 수 있다는 점이 장점이다.
3. 영속성
	- 데이터를 생성한 프로그램이 종료되더라도 사라지지 않는다.
	- 카프카는 전송받은 데이터를 메모리에 쓰는 것이 아닌, 파일 시스템에 저장한다.
		- 이거 느리다고 생각할 수 있는데, OS 레벨에서 파일 시스템 최대한 활용하여 속도를 증가시킨다.
			- 한번 읽은 파일 내용은 메모리에 저장시켰다가 다시 사용하는 방식으로 작동시킬 수 있다.
	- 브로커가 갑자기 죽어도 파일 시스템에 데이터가 저장되어 있기 때문에 이를 복구시켜 다시 작동시킬 수 있다.
4. 고가용성
	- 일반적으로 브로커 3대로 구성되고, 일부 서버에 문제가 발생해도 무중단으로 안전하고 지속적으로 데이터를 처리할 수 있다.
		- 프로듀서에서 데이터를 보냈을 때 메시지는 한개에 저장되는 것이 아니라, 여러개의 브로커에 복제하여 저장되게 된다.
		- 한개의 브로커에 장애가 발생하더라도 나머지 브로커가 남아있어 지속적으로 처리할 수 있도록 한다.
	- 컨슈머는 기존의 데이터를 가져가는 것이 아니라 남아있는 데이터를 바탕으로 가져갈 수 있도록 한다.
		- 지속적으로 데이터를 가져갈 수 있도록 한다.
	- 온 프레미스 서버랙이나 클라우드에서도 복제할 수 있는 환경을 제공한다.

## 빅 데이터 아키텍처의 종류와 카프카의 미래

### 초기 빅데이터 플랫폼 - 데이터 레이크
- 기존에는 원천 데이터 / 파생 데이터 / 서빙 데이터로 나누어져 있었다.
	- 원천 데이터는 소스로부터 받은 최초의 데이터라고 할 수 있다.
	- 원천 데이터를 프로세싱하여 만들어진 데이터를 파생 데이터라 한다.
	- 파생 데이터를 바탕으로 사용할 수 있도록 서빙 데이터로 만들어 저장되었다.
- 각 서비스에서 엔드 투 엔드로 데이터를 배치로 모으고, 이렇게 데이터 파이프라인을 운영해야 했다.
	- 유연하지 못하고, 실시간으로 생성되는 데이터의 인사이트를 서비스 어플리케이션에 빠르게 반영할 수 없었다.
	- 데이터의 히스토리를 파악하기 어려웠기 때문에, 데이터가 파편화되면서 데이터 정책을 지키기 어려웠다.

### 람다 아키텍처
- 크게 세가지 레이어로 이루어져 있다.
	- 배치 레이어
		- 배치 데이터를 모아 특정 시간마다 일괄 처리한다.
	- 서빙 레이어
		- 배치 레이어와 스피드 레이어에서 만들어진 데이터를 제공하도록 하는 레이어가 서빙 레이어이다.
	- 스피드 레이어
		- 서비스에서 생성되는 원천 데이터를 실시간으로 빠르게 분석하는 용도로 사용된다.
		- 이러한 스피드 레이어에 카프카가 위치하게 된다.
- 한계가 존재한다.
	- 데이터를 배치 처리하는 레이어와 실시간 처리하는 레이어가 분리되어 있다.
		- 분석 / 처리하는데 필요한 로직이 2벌로 각각의 레이어에 따로 존재해야 한다.
		- 배치 데이터와 실시간 데이터를 융합하여 처리할 때 유연하지 못하다.
			- 파편화가 발생하게 된다.
	- 1개의 로직을 추상화하여 배치 레이어와 스피드 레이어에 동일한 로직을 적용하는 방법이 제시되었다.
		- 서밍버드라는 오픈소스가 있긴 했는데, 해결되지는 않았다.
			- 어쨌거나 두 레이어가 따로 관리되기 때문에 그렇다.
			- 디버깅 / 테스트가 따로 이루어지게 되기 때문이다.

### 카파 아키텍처
- 스피드 레이어와 서빙 레이어로 구성된다.
	- 배치 레이어를 제거했다.
- 디버깅 / 배포의 파편화를 제거하기 위해 노력했다.
	- 모든 데이터를 스피드 레이어에서 처리하려고 하는 노력이 카파 아키텍처의 핵심이다.
- 스피드 레이어에서 일괄적으로 데이터를 처리하고, 서빙 레이어에 적합한 형태로 데이터를 보낼 수 있다는 것이 원칙이다.
	- 카프카를 활용해 이를 달성할 수 있다는 것이 가장 큰 특징이라고 할 수 있다.
		- 배치 데이터와 스트림 데이터를 모두 모으는 형태로 활용할 수 있어야 한다.
	- 이렇게 하기 위해 데이터를 배치 형태로 만들 수 있어야 한다.
		- 레코드 메시지 단위가 처음 / 가장 마지막 레코드 단위로 이루어져 있다.
			- 파티션에는 데이터가 순차적인 큐 모양으로 적재된다.
		- 스트림 데이터를 배치로 나타낼 수 있으면, 람다 아키텍처의 배치 레이어가 필요 없게 된다.
			- 스트림으로 들어온 데이터에서 배치 형태로 데이터 스냅샷을 확인하고, 이 데이터를 기반으로 배치 데이터 처리를 한다.
			- 변환 기록 로그를 남겨 배치 데이터를 기반으로 스트림 데이터와 배치 데이터를 함께 운영할 수 있게 된다.
- 로그 기반으로 데이터를 사용하고, 배치 데이터를 활용하기 위해서는 반드시 타임스탬프가 기록되어야 한다.
	- 카프카에서는 데이터 하나하나당 타임스탬프가 기록되고, 이 데이터를 기반으로 특정 기간의 데이터를 하나로 묶어 배치로 처리하게 된다.

### 배치 데이터 vs 스트림 데이터
- 배치 데이터
	- 한정된 데이터 처리를 수행한다.
	- 대규모 배치 데이터를 위해 일반적으로 분산 처리를 수행한다.
	- 분 / 시간 / 일 등으로 시간을 설정하고, 이를 묶어서 처리하기 위한 지연이 발생한다.
		- 복잡한 키의 조인을 수행하는 등의 활용도가 있다.
- 스트림 데이터
	- 단순한 키 조인만 수행하면서, 분 단위 이하의 지연만 발생한다.
	- 지속적으로 들어오는 데이터를 분산 처리로 처리하고, 무한한 데이터를 처리하게 된다.

### 스트림 데이터를 배치로 사용하는 법
- 구체화된 뷰를 활용하는 방식을 통해 사용할 수 있다.
- 특정 일시로 데이터를 뷰 형태로 가져와, 한 번의 배치처럼 사용한다.
	- key-value 스토어나 큰 용량의 데이터를 분산 처리할 수 있다.
- 로그(레코드)에 시간을 남기기 때문에 이러한 방법을 사용할 수 있다.

## 스트리밍 데이터 레이크
- 카파 아키텍처와 별개로 볼 수 있다.
	- 얘는 서빙 레이어까지 날아갔다.
	- 카프카가 배치 데이터도 처리하고, 서빙 데이터도 처리할 수 있댜!
- 스트림 레이어로 사용되는 카프카의 데이터 분석과 프로세싱을 오랜 기간 저장할 수 있고 사용할 수 있다면 필요 없지 않을까?
	- 카프카를 브로커로 사용하고, 자주 사용하는 데이터와 자주 사용하지 않는 데이터로 구분하는 등의 문제가 발생한다.
- 모든 데이터 아키텍처를 카프카로 통합한 미래는 이렇게 되지 않을까에 대한 예상이다.
- 이를 달성하기 위해서 여러가지 개선을 진행하고 있다.
	- 자주 접근하는 데이터와 자주 접근하지 않는 데이터를 분리하는 방식을 개발하는 점이다.
	- 브로커 어플리케이션이 인스턴스, 메모리에 점유하고 있는 것이 아닌 대용량의 오브젝트 스토리지로 저장하도록 한다.
		- 자주 사용하는 데이터는 메모리와 디스크, 자주 사용하지 않는 데이터는 오브젝트 스토리지에 할당하도록 하면 된다.
	- 이를 통해 더 많은 데이터를 카프카에서 운용할 수 있을 것이다.
	- 