---
title: 대형 서비스 아키텍처
feed: hide
---
## 기본적인 아키텍처
- API 서버 + Redis 붙인다.
	- 데이터 타입을 많이 지원해서 redis 많이 쓴다.
- 이후 RDB랑 mongo 단다.
	- 근데 mongo는 scalibility가 별로다.
	- 카산드라나 DynamoDB, BigTable, ScyllaDB같은걸 Key - Value 저장용으로 많이 쓴다.
	- nosql 운영이 매우 어렵고, 벤더 솔루션이나 매니지드 솔루션 사용한다.
		- 직접 설치해서 구성하는건 부담이 크다.
- 파일 시스템은 로컬 쓰는건 문제 없고, 공유 파일 시스템 사용하는 것이 문제가 된다.
	- API 서버는 로드밸런싱이 된다.
	- MSA이 경우 L7 스위치로 LB 쓴다.
- 파일 공유하기 위해서 NFS 사용한다.
	- 소프트웨어의 경우는 속도가 안나와서 하드웨어로 쓰거나, GFS같은거 쓴다.
	- Blob Storage (S3, GCS) 쓰는데, 스케일링에는 좋은데 성능이 구리다.
		- 성능 필요한걸 NFS로 보낸다.
- API 콜 들어오면 인증을 해야한다.
	- 인증하는 시스템을 IDM (Identity Management System)이라 한다.
	- OAuth Provider 많이 사용하고, DB로도 많이 사용한다.
	- 이 시스템 설계가 많이 망가진다.
		- 중앙 집중화된 시스템을 만들어야 하는데 그룹 설계 잘못하는 경우가 많다.
		- ID시스템 통합 안되고 여러개 있는 경우가 많다.
		- 사용자가 중복적으로 로그인을 해야하는 상황이 발생하게 된다.
	- 다른 시스템과 협업할 수 있는 시스템을 구성할 수 있어야 한다.
		- [WSO2 identity Service]([https://wso2.com/identity-server/](https://wso2.com/identity-server/)) 찾아보면 좋다.
			- 근데 production service에는 좀 애매하다.
- 요즘은 API Gateway도 사용한다.
	- 여기에 CDN만 서빙하면 완성이다.
	- 이게 백엔드 시스템이다.
- 여기에 대한 인프라가 필요하다.
	- BareMetal, VM, K8s를 사용해 적용시킬 수 있다.
	- 각각의 용도가 다르게 된다.
		- 보안 필요한 경우 baremetal 필요하다.
		- vm도 편한데, 요즘은 k8s로 많이 가는 편이다. 
	- 추가로, 서드 파티 매니지 서비스를 사용한다.
		- Datadog, RedisLabs 등을 사용할 수 있다.
- 이 뒤에  Operating System 붙인다.
	- CI/CD (젠킨스 / argocd가 스탠다드)
	- Logging(ELK)
	- Monitoring(Promethus + Grafana)
		- 이거 클러스터링이 안되서, 그냥 서드파티로 많이 뺀다.
		- 클라우드 서비스 많이 쓰게 된다.
			- datadog, newrelic 좋은데 조온나 비싸다.

## 빅데이터 분석 시스템
- 위의 기본적인 아키텍처에서 데이터를 뽑아오자.
	- 뽑은 데이터를 데이터 웨어하우스 / 데이터 레이크로 보낸다.
	- 빅데이터 분석 시스템이 된다.
- 백엔드로부터 데이터를 가져오는 것을 ETL (Extract Transformation and Loading)이라 한다.
- 예전에는 소스가 RDBMS, FTP였는데, 요즘은 SaaS가 데이터 소스가 된다.
	- 모던 툴들은 SaaS에 집중하게 된다.
	- 하둡, 스파크도 포함한다.
- 이렇게 데이터를 가져오는 것을 Ingestion이라 한다.
- Data Warehouse / DataLake 시스템을 만든다.
	- Oracle Exadata가 강하다
		- 정형 데이터만 된다.
	- 빅데이터 시대가 되면서 비정형 데이터가 발생했고, 엄청나게 많은 데이터가 발생했다.
		- 하둡과 스파크가 주로 사용되게 된다.

### Data Warehouse / Lake
- data warehouse는 저장을 한 후, 추가적인 데이터 웨어하우스를 만들어 비즈니스에서 필요한 데이터만 가져오도록 한다.
	- data mart라 하고, 이를 warehouse와 계속 연결하도록 한다.
	- mart에 대한 대시보드가 필요하고, 이를 Business Intelligence 솔루션으로 처리한다.
		- tableu, Looker, power BI가 주로 사용된다.
- warehouse나 lake는 분석하는 데이터 분석 팀을 필요로 한다.
	- 세일즈 팀은 분석팀으로 요청해서 받아와야 한다.
	- 그리고 분석 팀은 도메인 지식이 부족해서 bottleneck이 되게 된다.
	- 데이터 분석팀은 회사의 공유 팀이고, 돈을 버는 조직이 아니다.
		- 투자 자원에 한계가 있다.

### Data Mesh
- 각각의 부서 별로 데이터 엔지니어링 팀을 넣어버리도록 하는 것이다.
	- 예산에 대한 부담이 줄고, 전문성이 올라간다.
	- 다른 팀의 정보를 필요로 할 때, ETL을 또 해야 해서 중앙 집중화 시켜야 한다는 얘기가 나온다.
		- 예전에는 카피를 해왔어야 했는데, 요즘은 federation이라고 remote로 쿼리 같이 때릴 수 있도록 할 수 있다.
		- 팀을 이렇게 운영해도 전체 팀을 snowflake에 구성하도록 할 수 있는 것이다.
- 데이터를 API로 뽑도록 한다.
	- 이를 DaaS 서비스라고 한다.
		- 기업은 갖고 있는 데이터가 어딨는지를 모른다.
- 다음 단계로 데이터 거버넌스 / 데이터 카탈로그가 된다.
	- 데이터의 정보가 카탈로그로 등록이 된다.
		- table / column의 description을 가져오도록 할 수 있다.
	- 구글 빅데이터 시스템의 plx같은 시스템을 통해 DB를 고르고,  정보들을 모두 가져올 수 있도록 할 수 있게 되는 것이다.
- 원하는 데이터를 원하는 순간에 볼 수 있도록 하는 것이 데이터 분석의 핵심이다.
- Access Control도 중요하다.
	- 흩어져 있는 DB의 column, table 단위로 접근 관리를 할 수 있도록 할 수 있어야 한다.
- ETL을 통해서 데이터가 이동을 하는데, 이러한 이동 흐름을 볼 수 있어야 한다.
	- 데이터의 이동을 확인하는 것을 Data Lineage라 한다.
		- 어느 테이블에서 어느 테이블로 이동했는지 기록들을 모두 확인할 수 있도록 한다.
- 중앙 집중형에서 분산화, 셀프 서비스화가 트렌드라고 할 수 있다.
	- 요즘은 SQL만 쓰면 비즈니스 하는 사람들도 빅 데이터를 분석을 할 수 있도록 하는 것이다.
	- 구글 시트 연결해서 엑셀로도 할 수 있도록 쉬워지고 있는 것이다.
		- 진입 장벽이 낮아지고, 누구나 할 수 있는 쪽으로 움직이는 것이다.

## 머신러닝의 활용
- 이제 API / Big Data에서 오는 데이터로 훈련 데이터를 사용하는 것이다.
	- 이를 통해 모델을 만들고, 이걸 다시 API로 집어 넣는 것이다.
	- 모델을 다시 외부로 서빙하도록 하는 것이다.
- API - 모델로 이루어지는 서빙 구조를 ML System이라 한다.
	- FDS (이상 탐지) 등에서 주로 사용되게 된다.
	- 마케팅 여부 등을 줄 수 있는 판단 모델도 생기고 있다.
- lifetime 모델이라고, 90일동안 얼마나 사용할지를 고려하는 문제도 있다.
	- 이를 바탕으로 타겟팅 마케팅을 한다.
	- 산업마다 타겟팅이 달라지게 된다.
- ML 시스템은 신나게 복잡하다.



- 관련 글은 이거 한번 읽어보면 된다. [분산형 데이터 분석 아키텍처-데이터 매쉬](https://bcho.tistory.com/1379)
	- [[분산형 데이터 분석 아키텍처]]
- 구현 구조가 어떻게 구성되는지랑은 조금은 다른 얘기가 된다.
- 데이터 레이크에서 슈퍼 컴퓨터 등이 필요로 하는 순간들이 있다.
	- DNA 시퀀싱같은게 그렇게 발생한다.
